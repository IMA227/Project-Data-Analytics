{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8XDyONq0oQM"
      },
      "source": [
        "# Dummy model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X-kQhlGaymnt",
        "outputId": "8f6a66cc-97b7-4786-bc34-99989b5d4e08"
      },
      "outputs": [],
      "source": [
        "# Loading Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_recall_fscore_support,\n",
        "    roc_curve,\n",
        "    precision_recall_curve,\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "\n",
        "# basic config (paths + split settings)\n",
        "DATA_PATH = \"/content/Sample_500_stratified.xlsx\"\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "MIN_COUNT_PER_CLASS = 2\n",
        "RARE_LABEL = \"__RARE__\"\n",
        "\n",
        "\n",
        "def make_text_X(df: pd.DataFrame, feature_cols):\n",
        "    # combine selected text columns into one string per row\n",
        "    X = df[feature_cols].copy()\n",
        "    for c in feature_cols:\n",
        "        X[c] = X[c].fillna(\"\").astype(str)\n",
        "    return X.agg(\" \".join, axis=1)\n",
        "\n",
        "\n",
        "def squash_rare_classes(y: pd.Series, min_count=2, rare_label=\"__RARE__\"):\n",
        "    # collapse very small classes into a single fallback label\n",
        "    y = y.astype(str).str.strip()\n",
        "    vc = y.value_counts(dropna=False)\n",
        "    rare = vc[vc < min_count].index\n",
        "    if len(rare) == 0:\n",
        "        return y\n",
        "    return y.where(~y.isin(rare), other=rare_label)\n",
        "\n",
        "\n",
        "def plot_binary_roc_pr_from_scores(y_true_bin: np.ndarray, scores: np.ndarray, titel: str):\n",
        "    # ROC + PR curves for binary case\n",
        "    try:\n",
        "        fpr, tpr, _ = roc_curve(y_true_bin, scores)\n",
        "        auc_val = roc_auc_score(y_true_bin, scores)\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr)\n",
        "        plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
        "        plt.xlabel(\"False Positive Rate\")\n",
        "        plt.ylabel(\"True Positive Rate\")\n",
        "        plt.title(f\"{titel} ROC (AUC={auc_val:.3f})\")\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"{titel}: ROC übersprungen ({e})\")\n",
        "\n",
        "    try:\n",
        "        prec, rec, _ = precision_recall_curve(y_true_bin, scores)\n",
        "        ap = average_precision_score(y_true_bin, scores)\n",
        "        plt.figure()\n",
        "        plt.plot(rec, prec)\n",
        "        plt.xlabel(\"Recall\")\n",
        "        plt.ylabel(\"Precision\")\n",
        "        plt.title(f\"{titel} PR (AP={ap:.3f})\")\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"{titel}: PR übersprungen ({e})\")\n",
        "\n",
        "\n",
        "def plot_multiclass_micro_roc_pr_from_scores(y_true: np.ndarray, score_mat: np.ndarray, class_order, titel: str):\n",
        "    # micro-averaged ROC + PR for multiclass setting\n",
        "    try:\n",
        "        present = np.unique(y_true)\n",
        "        present = np.array([c for c in present if c in set(class_order)], dtype=object)\n",
        "\n",
        "        if len(present) < 2:\n",
        "            print(f\"{titel}: Kurven übersprungen (<2 Klassen im Test)\")\n",
        "            return\n",
        "\n",
        "        idx = [np.where(class_order == c)[0][0] for c in present]\n",
        "        scores_sub = score_mat[:, idx]\n",
        "        y_bin = label_binarize(y_true, classes=present)\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(y_bin.ravel(), scores_sub.ravel())\n",
        "        auc_micro = roc_auc_score(y_bin, scores_sub, average=\"micro\")\n",
        "        auc_macro = roc_auc_score(y_bin, scores_sub, average=\"macro\")\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr)\n",
        "        plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
        "        plt.xlabel(\"False Positive Rate\")\n",
        "        plt.ylabel(\"True Positive Rate\")\n",
        "        plt.title(f\"{titel} ROC (micro={auc_micro:.3f}, macro={auc_macro:.3f})\")\n",
        "        plt.show()\n",
        "\n",
        "        prec, rec, _ = precision_recall_curve(y_bin.ravel(), scores_sub.ravel())\n",
        "        ap_micro = average_precision_score(y_bin, scores_sub, average=\"micro\")\n",
        "        ap_macro = average_precision_score(y_bin, scores_sub, average=\"macro\")\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(rec, prec)\n",
        "        plt.xlabel(\"Recall\")\n",
        "        plt.ylabel(\"Precision\")\n",
        "        plt.title(f\"{titel} PR (micro={ap_micro:.3f}, macro={ap_macro:.3f})\")\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"{titel}: Multiclass-Kurven übersprungen ({e})\")\n",
        "\n",
        "\n",
        "def run_dummy_task(df: pd.DataFrame, feature_cols, target_col: str, task_name: str, plot_curves=True):\n",
        "    # copy + minimal cleaning\n",
        "    d = df.copy()\n",
        "    d = d.dropna(subset=[target_col])\n",
        "    d[target_col] = d[target_col].astype(str).str.strip()\n",
        "    d = d[d[target_col] != \"\"]\n",
        "\n",
        "    if len(d) < 10:\n",
        "        print(f\"{task_name}: zu wenige Zeilen (n={len(d)})\")\n",
        "        return\n",
        "\n",
        "    # build text input and target\n",
        "    X = make_text_X(d, feature_cols)\n",
        "    y = d[target_col].astype(str)\n",
        "\n",
        "    # reduce rare labels to stabilize evaluation\n",
        "    y = squash_rare_classes(y, min_count=MIN_COUNT_PER_CLASS, rare_label=RARE_LABEL)\n",
        "\n",
        "    if y.nunique() < 2:\n",
        "        print(f\"{task_name}: nur eine Klasse nach Bereinigung\")\n",
        "        return\n",
        "\n",
        "    # stratified split if feasible\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
        "        )\n",
        "    except Exception:\n",
        "        # fallback without stratification\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
        "        )\n",
        "\n",
        "    # majority baseline\n",
        "    model = DummyClassifier(strategy=\"most_frequent\", random_state=RANDOM_STATE)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"macro\", zero_division=0)\n",
        "\n",
        "    print(task_name)\n",
        "    print(f\"n_train={len(y_train)}, n_test={len(y_test)}, n_classes={y.nunique()}\")\n",
        "    print(f\"Accuracy:  {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f} (macro)\")\n",
        "    print(f\"Recall:    {rec:.4f} (macro)\")\n",
        "    print(f\"F1:        {f1:.4f} (macro)\")\n",
        "\n",
        "    if not plot_curves:\n",
        "        return\n",
        "\n",
        "    # probability-based curves \n",
        "    try:\n",
        "        proba = model.predict_proba(X_test)\n",
        "        class_order = model.classes_\n",
        "\n",
        "        if len(class_order) == 2:\n",
        "            # binary case\n",
        "            pos_label = class_order[1]\n",
        "            y_true_bin = (np.asarray(y_test) == pos_label).astype(int)\n",
        "            plot_binary_roc_pr_from_scores(y_true_bin, proba[:, 1], task_name)\n",
        "        else:\n",
        "            # multiclass case\n",
        "            plot_multiclass_micro_roc_pr_from_scores(np.asarray(y_test), proba, class_order, task_name)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"{task_name}: Kurven übersprungen ({e})\")\n",
        "\n",
        "\n",
        "# load data\n",
        "df = pd.read_excel(DATA_PATH)\n",
        "print(f\"Datei geladen: {DATA_PATH}\")\n",
        "print(f\"Rows: {len(df)} | Cols: {len(df.columns)}\")\n",
        "display(df.head(3))\n",
        "\n",
        "\n",
        "# baseline tasks for different label dimensions\n",
        "\n",
        "run_dummy_task(\n",
        "    df,\n",
        "    feature_cols=[\"desc_1\", \"desc_2\"],\n",
        "    target_col=\"cuisine_region\",\n",
        "    task_name=\"DummyClassifier: cuisine_region\",\n",
        "    plot_curves=True,\n",
        ")\n",
        "\n",
        "run_dummy_task(\n",
        "    df,\n",
        "    feature_cols=[\"desc_1\", \"desc_2\", \"title\"],\n",
        "    target_col=\"concept_format\",\n",
        "    task_name=\"DummyClassifier: concept_format\",\n",
        "    plot_curves=True,\n",
        ")\n",
        "\n",
        "run_dummy_task(\n",
        "    df,\n",
        "    feature_cols=[\"opening_hours\"],\n",
        "    target_col=\"opening_class_label\",\n",
        "    task_name=\"DummyClassifier: opening_class_label\",\n",
        "    plot_curves=True,\n",
        ")\n",
        "\n",
        "run_dummy_task(\n",
        "    df,\n",
        "    feature_cols=[\"title\"],\n",
        "    target_col=\"Chain-Indep\",\n",
        "    task_name=\"DummyClassifier: Chain-Indep\",\n",
        "    plot_curves=True,\n",
        ")\n",
        "\n",
        "run_dummy_task(\n",
        "    df,\n",
        "    feature_cols=[\"services\"],\n",
        "    target_col=\"Services_Label\",\n",
        "    task_name=\"DummyClassifier: Services_Label\",\n",
        "    plot_curves=True,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
