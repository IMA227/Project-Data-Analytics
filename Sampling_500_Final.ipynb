{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c156d-e104-464e-8ef0-460e3cf6aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading libraries:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def strat_sample_city_star(\n",
    "    df,\n",
    "    n=500,\n",
    "    city_col=\"city\",\n",
    "    star_col=\"star_count\",\n",
    "    top_n_cities=15,\n",
    "    seed=42,\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    d = df.copy()\n",
    "\n",
    "    # Basic cleanup for the relevant columns\n",
    "    d[city_col] = d[city_col].astype(str).str.strip()\n",
    "    d[star_col] = pd.to_numeric(d[star_col], errors=\"coerce\")\n",
    "\n",
    "    # Keep only rows where both city and star_count exist\n",
    "    d = d.dropna(subset=[city_col, star_col]).copy()\n",
    "    if d.empty:\n",
    "        raise ValueError(\"No rows left after dropping missing city/star values.\")\n",
    "\n",
    "    d[star_col] = d[star_col].astype(int)\n",
    "\n",
    "    # Top cities as separate buckets, everything else = Other_Cities\n",
    "    top_cities = d[city_col].value_counts().head(top_n_cities).index\n",
    "    d[\"city_bucket\"] = np.where(d[city_col].isin(top_cities), d[city_col], \"Other_Cities\")\n",
    "\n",
    "    # Star groups: 0/1/2 and everything 3+ merged into one group\n",
    "    d[\"star_group\"] = np.where(d[star_col] >= 3, 3, d[star_col])\n",
    "\n",
    "    # Stratum = (city bucket, star group)\n",
    "    d[\"stratum\"] = list(zip(d[\"city_bucket\"], d[\"star_group\"]))\n",
    "\n",
    "    # Stratum sizes\n",
    "    counts = d.groupby(\"stratum\").size()\n",
    "    N = int(counts.sum())\n",
    "    if N == 0:\n",
    "        raise ValueError(\"No valid observations available.\")\n",
    "\n",
    "    # Proportional allocation\n",
    "    n_prop = (counts / N) * n\n",
    "    n_h = np.floor(n_prop).astype(int)\n",
    "\n",
    "    # Distribute rounding remainder (largest fractional parts first)\n",
    "    frac = (n_prop - np.floor(n_prop)).sort_values(ascending=False)\n",
    "    rest = int(n - n_h.sum())\n",
    "\n",
    "    if rest > 0:\n",
    "        for s in frac.index:\n",
    "            if rest == 0:\n",
    "                break\n",
    "            if n_h.loc[s] < counts.loc[s]:\n",
    "                n_h.loc[s] += 1\n",
    "                rest -= 1\n",
    "    elif rest < 0:\n",
    "        frac2 = (n_prop - np.floor(n_prop)).sort_values(ascending=True)\n",
    "        for s in frac2.index:\n",
    "            if rest == 0:\n",
    "                break\n",
    "            if n_h.loc[s] > 0:\n",
    "                n_h.loc[s] -= 1\n",
    "                rest += 1\n",
    "\n",
    "    # One random number per row:\n",
    "    d[\"_u\"] = rng.random(len(d))\n",
    "\n",
    "    # Sample inside each stratum\n",
    "    parts = []\n",
    "    for s, k in n_h.items():\n",
    "        k = int(k)\n",
    "        if k <= 0:\n",
    "            continue\n",
    "        tmp = d[d[\"stratum\"] == s].nsmallest(k, \"_u\")\n",
    "        parts.append(tmp)\n",
    "\n",
    "    if parts:\n",
    "        sample = pd.concat(parts, axis=0).copy()\n",
    "    else:\n",
    "        sample = d.iloc[0:0].copy()\n",
    "\n",
    "    sample = sample.drop(columns=[\"_u\"])\n",
    "\n",
    "    # Enforce exactly n rows \n",
    "    if len(sample) > n:\n",
    "        sample = sample.sample(n=n, random_state=seed)\n",
    "    elif len(sample) < n:\n",
    "        missing = n - len(sample)\n",
    "        rest_df = d.loc[~d.index.isin(sample.index)].copy()\n",
    "        if not rest_df.empty:\n",
    "            extra = rest_df.sample(n=min(missing, len(rest_df)), random_state=seed).drop(columns=[\"_u\"])\n",
    "            sample = pd.concat([sample, extra], axis=0)\n",
    "\n",
    "        if len(sample) > n:\n",
    "            sample = sample.sample(n=n, random_state=seed)\n",
    "\n",
    "    sample = sample.reset_index(drop=True)\n",
    "\n",
    "    # Allocation table for documentation / reporting\n",
    "    alloc = (\n",
    "        pd.DataFrame({\"stratum\": counts.index, \"N_h\": counts.values})\n",
    "        .merge(pd.DataFrame({\"stratum\": n_h.index, \"n_h\": n_h.values}), on=\"stratum\", how=\"left\")\n",
    "        .fillna({\"n_h\": 0})\n",
    "    )\n",
    "    alloc[\"n_h\"] = alloc[\"n_h\"].astype(int)\n",
    "    alloc[[\"city_bucket\", \"star_group\"]] = pd.DataFrame(alloc[\"stratum\"].tolist(), index=alloc.index)\n",
    "    alloc = alloc.drop(columns=[\"stratum\"]).sort_values([\"n_h\", \"N_h\"], ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return sample, alloc\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_excel(\n",
    "        r\"\\PDA_DATA\\Restaurants_Data.xlsx\",\n",
    "        sheet_name=\"Data_Filtered_Primary\",\n",
    "    )\n",
    "\n",
    "    sample_500, alloc_table = strat_sample_city_star(\n",
    "        df,\n",
    "        n=500,\n",
    "        city_col=\"city\",\n",
    "        star_col=\"star_count\",\n",
    "        top_n_cities=15,\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "    sample_500.to_excel(\"sample_500_city_star.xlsx\", index=False)\n",
    "    alloc_table.to_csv(\"allocation_city_star.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
